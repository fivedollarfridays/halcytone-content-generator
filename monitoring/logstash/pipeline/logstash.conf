# Logstash pipeline configuration for Halcytone logs

input {
  # Filebeat input
  beats {
    port => 5044
  }

  # Direct TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp", "application"]
  }

  # UDP input for application logs
  udp {
    port => 5000
    codec => json_lines
    tags => ["udp", "application"]
  }

  # Syslog input
  syslog {
    port => 5001
    tags => ["syslog"]
  }
}

filter {
  # Parse container logs from Filebeat
  if [container] {
    # Extract container information
    mutate {
      add_field => { "service" => "%{[container][name]}" }
      add_field => { "container_id" => "%{[container][id]}" }
      add_field => { "container_image" => "%{[container][image][name]}" }
    }

    # Parse JSON logs if they're JSON formatted
    if [message] =~ /^\s*{.*}\s*$/ {
      json {
        source => "message"
        target => "app"
        add_tag => ["json_parsed"]
      }
    }
  }

  # Process Halcytone application logs
  if [service] =~ /halcytone/ or [logger] =~ /halcytone/ {
    # Add service tag
    mutate {
      add_tag => ["halcytone", "application"]
    }

    # Parse application-specific fields
    if [app] {
      # Extract structured fields from application logs
      if [app][level] {
        mutate {
          add_field => { "log_level" => "%{[app][level]}" }
        }
      }

      if [app][logger] {
        mutate {
          add_field => { "logger_name" => "%{[app][logger]}" }
        }
      }

      if [app][request_id] {
        mutate {
          add_field => { "request_id" => "%{[app][request_id]}" }
        }
      }

      if [app][user_id] {
        mutate {
          add_field => { "user_id" => "%{[app][user_id]}" }
        }
      }

      if [app][correlation_id] {
        mutate {
          add_field => { "correlation_id" => "%{[app][correlation_id]}" }
        }
      }

      # Extract performance metrics
      if [app][duration_seconds] {
        mutate {
          convert => { "[app][duration_seconds]" => "float" }
        }
      }

      if [app][status_code] {
        mutate {
          convert => { "[app][status_code]" => "integer" }
        }
      }

      # Parse exception information
      if [app][exception] {
        mutate {
          add_field => { "exception_type" => "%{[app][exception][type]}" }
          add_field => { "exception_message" => "%{[app][exception][message]}" }
          add_tag => ["exception"]
        }
      }
    }

    # Categorize log levels
    if [log_level] {
      if [log_level] == "ERROR" or [log_level] == "CRITICAL" {
        mutate { add_tag => ["error"] }
      } else if [log_level] == "WARNING" or [log_level] == "WARN" {
        mutate { add_tag => ["warning"] }
      } else if [log_level] == "DEBUG" {
        mutate { add_tag => ["debug"] }
      }
    }

    # Content generation specific processing
    if [app][operation] == "content_generation" {
      mutate {
        add_tag => ["content_generation"]
        add_field => { "content_type" => "%{[app][content_type]}" }
        add_field => { "template" => "%{[app][template]}" }
      }

      if [app][quality_score] {
        mutate {
          convert => { "[app][quality_score]" => "float" }
        }
      }
    }

    # External API call processing
    if [app][operation] == "external_api_call" {
      mutate {
        add_tag => ["external_api"]
        add_field => { "external_service" => "%{[app][external_service]}" }
        add_field => { "external_endpoint" => "%{[app][external_endpoint]}" }
      }
    }

    # Database operation processing
    if [app][operation] == "database_operation" {
      mutate {
        add_tag => ["database"]
        add_field => { "database_operation" => "%{[app][database_operation]}" }
        add_field => { "database_table" => "%{[app][database_table]}" }
      }

      if [app][rows_affected] {
        mutate {
          convert => { "[app][rows_affected]" => "integer" }
        }
      }
    }
  }

  # Process HTTP access logs
  if [fields][log_type] == "access" or "access" in [tags] {
    grok {
      match => {
        "message" => "%{COMBINEDAPACHELOG}"
      }
      add_tag => ["access_log"]
    }

    # Convert response size and response time
    if [bytes] {
      mutate {
        convert => { "bytes" => "integer" }
      }
    }

    # Extract status code category
    if [response] {
      if [response] >= 200 and [response] < 300 {
        mutate { add_tag => ["success"] }
      } else if [response] >= 400 and [response] < 500 {
        mutate { add_tag => ["client_error"] }
      } else if [response] >= 500 {
        mutate { add_tag => ["server_error"] }
      }
    }
  }

  # Prometheus metrics logs
  if [logger_name] =~ /prometheus/ {
    mutate {
      add_tag => ["metrics", "prometheus"]
    }
  }

  # Health check logs - reduce verbosity
  if [app][request_path] =~ /health|ready|live|metrics/ {
    if [log_level] != "ERROR" and [log_level] != "CRITICAL" {
      drop { }
    }
  }

  # Add timestamp parsing
  if [app][timestamp] {
    date {
      match => [ "[app][timestamp]", "ISO8601" ]
      target => "@timestamp"
    }
  } else if [@timestamp] {
    # Use existing timestamp
  } else {
    # Add current timestamp if none exists
    ruby {
      code => "event.set('@timestamp', Time.now)"
    }
  }

  # Add environment information
  mutate {
    add_field => {
      "environment" => "%{ENVIRONMENT:production}"
      "cluster" => "halcytone-production"
      "version" => "%{APP_VERSION:unknown}"
    }
  }

  # Cleanup fields
  mutate {
    remove_field => [ "beat", "input", "agent", "ecs", "host" ]
  }

  # Add GeoIP for IP addresses (if present)
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}

output {
  # Output to Elasticsearch with dynamic index
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "halcytone-logs-%{+YYYY.MM.dd}"
    template_name => "halcytone-logs"
    template => "/usr/share/logstash/templates/halcytone-template.json"
    template_overwrite => true

    # Document ID to prevent duplicates
    document_id => "%{[@metadata][fingerprint]}"

    # Retry configuration
    retry_on_conflict => 3
    retry_initial_interval => 2
    retry_max_interval => 64
    retry_on_failure => 5
  }

  # Separate index for errors
  if "error" in [tags] or "exception" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "halcytone-errors-%{+YYYY.MM.dd}"
      template_name => "halcytone-errors"
      template => "/usr/share/logstash/templates/halcytone-error-template.json"
      template_overwrite => true
    }
  }

  # Separate index for performance metrics
  if "content_generation" in [tags] or "external_api" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "halcytone-performance-%{+YYYY.MM.dd}"
    }
  }

  # Debug output for development
  if [environment] == "development" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }

  # Dead letter queue for failed documents
  if "_grokparsefailure" in [tags] or "_jsonparsefailure" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "halcytone-failed-logs-%{+YYYY.MM.dd}"
    }
  }
}